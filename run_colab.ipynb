{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tuxliri/RL_rocket/blob/master/run_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4Uab7q5v8nS"
      },
      "outputs": [],
      "source": [
        "!git clone --branch master https://github.com/Tuxliri/RL_rocket.git\n",
        "\n",
        "!cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWzlYmiY141N"
      },
      "outputs": [],
      "source": [
        "!pip install stable-baselines3==1.5.0\n",
        "\n",
        "!pip install -e RL_rocket/.\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/RL_rocket')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiCJgT535o_N"
      },
      "source": [
        "**IMPORT ALL THE NEEDED PACKAGES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sb-HCUk1v2KO"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from genericpath import exists\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import gym\n",
        "import wandb\n",
        "import numpy as np\n",
        "import stable_baselines3\n",
        "\n",
        "from stable_baselines3 import PPO\n",
        "from tensorboard import program\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.utils import set_random_seed\n",
        "from wandb.integration.sb3 import WandbCallback\n",
        "from stable_baselines3.common.vec_env.dummy_vec_env import DummyVecEnv\n",
        "\n",
        "import my_environment\n",
        "from my_environment.wrappers.wrappers import RecordVideoFigure, RewardAnnealing\n",
        "from gym.wrappers import TimeLimit\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpwKGvd_v4sF"
      },
      "source": [
        "# Execute the training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0whknuJU6tIm"
      },
      "source": [
        "**Environment definition**\n",
        "\n",
        "Here we define the environment, setting up the initial conditions, the range over which the initial conditions are generated and the timestep of the simulation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MC0kpJp6Yuf"
      },
      "outputs": [],
      "source": [
        "# Choose the folder to store tensorboard logs\n",
        "TENSORBOARD_LOGS_DIR = \"./logs\"\n",
        "\n",
        "config = {\n",
        "    \"env_id\" : \"my_environment/Falcon3DOF-v0\",\n",
        "    \"policy_type\": \"MlpPolicy\",\n",
        "    \"total_timesteps\": int(2e6),\n",
        "    \"timestep\" : 0.05,\n",
        "    \"max_time\" : 100,\n",
        "    \"RANDOM_SEED\" : 42,\n",
        "    \"initial_conditions\" : [-1600, 2000, np.pi*3/4, 180, -90, 0, 50e3],\n",
        "    \"initial_conditions_range\" : [5,50,0,0,0,0,1e3],\n",
        "    \"reward_coefficients\" : {\n",
        "                            \"alfa\" : -0.01, \n",
        "                            \"beta\" : 0,\n",
        "                            \"delta\" : -5,\n",
        "                            \"eta\" : 0.2,\n",
        "                            \"gamma\" : -10,\n",
        "                            \"kappa\" : 10,\n",
        "                            \"xi\" : 0.004,\n",
        "                            \"waypoint\" : 30,\n",
        "                            \"landing_radius\" : 30\n",
        "                            },\n",
        "}\n",
        "\n",
        "config[\"max_ep_timesteps\"] = int(config[\"max_time\"]/config[\"timestep\"])\n",
        "config[\"eval_freq\"] = int(config[\"total_timesteps\"]/20)\n",
        "\n",
        "run = wandb.init(\n",
        "    project=\"RL_rocket\",\n",
        "    config=config,\n",
        "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
        "    monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
        ")\n",
        "\n",
        "def make_env():\n",
        "    env = gym.make(\n",
        "    config[\"env_id\"],\n",
        "    IC=config[\"initial_conditions\"],\n",
        "    ICRange=config[\"initial_conditions_range\"],\n",
        "    timestep=config[\"timestep\"],\n",
        "    seed=config[\"RANDOM_SEED\"],\n",
        "    reward_coeff=config[\"reward_coefficients\"]\n",
        "    )\n",
        "    \n",
        "    # Define a new custom action space with only three actions:\n",
        "    # - no thrust\n",
        "    # - max thrust gimbaled right\n",
        "    # - max thrust gimbaled left\n",
        "    # - max thrust downwards\n",
        "    \n",
        "    # env = DiscreteActions3DOF(env)\n",
        "    env = TimeLimit(env, max_episode_steps=config[\"max_ep_timesteps\"])\n",
        "    env = Monitor(\n",
        "        env,\n",
        "        allow_early_resets=True,\n",
        "        filename=\"logs_PPO\",\n",
        "        )\n",
        "    return env"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.run.log_code(root = '/content/RL_rocket/my_environment', name = 'environment')"
      ],
      "metadata": {
        "id": "WVl1xBs6156_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZ1ZGrab6TJh"
      },
      "outputs": [],
      "source": [
        "env=make_env()\n",
        "model = PPO(\n",
        "    config[\"policy_type\"],\n",
        "    env,\n",
        "    tensorboard_log=f\"runs/{run.id}\",\n",
        "    verbose=1,\n",
        "    seed=config[\"RANDOM_SEED\"],\n",
        "    ent_coef=0.01,\n",
        "    )\n",
        "\n",
        "def make_eval_env(training_env = env):\n",
        "        return RecordVideoFigure(training_env, video_folder=f\"videos/{run.id}\",\n",
        "        image_folder=f\"images/{run.id}\", episode_trigger= lambda x: x%5==0 )\n",
        "\n",
        "  \n",
        "eval_env = DummyVecEnv([make_eval_env])\n",
        "            \n",
        "callbacksList = [\n",
        "    EvalCallback(\n",
        "        eval_env,\n",
        "        eval_freq = config[\"eval_freq\"],\n",
        "        n_eval_episodes = 5,\n",
        "        render=False,\n",
        "        deterministic=True,\n",
        "        ),\n",
        "    WandbCallback(\n",
        "        model_save_path=f\"models/{run.id}\",\n",
        "        verbose=2,\n",
        "        gradient_save_freq=10000\n",
        "        )\n",
        "    ]\n",
        "\n",
        "model.learn(\n",
        "    total_timesteps=config[\"total_timesteps\"],\n",
        "    callback=callbacksList\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6djos42SjrKv"
      },
      "outputs": [],
      "source": [
        "def make_env(config):\n",
        "    env = gym.make(\n",
        "    config[\"env_id\"],\n",
        "    IC=config[\"initial_conditions\"],\n",
        "    ICRange=config[\"initial_conditions_range\"],\n",
        "    timestep=config[\"timestep\"],\n",
        "    seed=config[\"RANDOM_SEED\"]\n",
        "    )\n",
        "    # Anneal the reward (remove v_targ following reward)\n",
        "    env = RewardAnnealing(env, thrust_penalty = 0.004)\n",
        "\n",
        "    # Define a new custom action space with only three actions:\n",
        "    # - no thrust\n",
        "    # - max thrust gimbaled right\n",
        "    # - max thrust gimbaled left\n",
        "    # - max thrust downwards\n",
        "    \n",
        "    # env = DiscreteActions3DOF(env)\n",
        "    env = TimeLimit(env, max_episode_steps=config[\"max_ep_timesteps\"])\n",
        "    return env\n",
        "\n",
        "env=make_env(config)\n",
        "\n",
        "def make_eval_env(training_env=env):\n",
        "    return RecordVideoFigure(training_env, video_folder=f\"videos/{run.id}\",\n",
        "            image_folder=f\"images/{run.id}\", episode_trigger= lambda x: x%5==0 )\n",
        "\n",
        "eval_env = DummyVecEnv([make_eval_env])\n",
        "\n",
        "callbacksList = [\n",
        "    EvalCallback(\n",
        "        eval_env,\n",
        "        eval_freq = config[\"eval_freq\"],\n",
        "        n_eval_episodes = 5,\n",
        "        render=False,\n",
        "        deterministic=True,\n",
        "        ),\n",
        "    WandbCallback(\n",
        "        model_save_path=f\"models/{run.id}\",\n",
        "        verbose=2,\n",
        "        gradient_save_freq=10000\n",
        "        ),\n",
        "]     \n",
        "    \n",
        "model.set_env(env)\n",
        "# model.learn(\n",
        "#     total_timesteps=config[\"total_timesteps\"]*2,\n",
        "#     callback=callbacksList\n",
        "# )\n",
        "\n",
        "run.finish()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "run_my_environment.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.7.13 ('thesis_env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "cb2bed79003d04db150c2bac0cc69c4a81f9badb372e6d411ccf76fa514c45a4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}